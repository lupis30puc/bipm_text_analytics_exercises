{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "tws",
      "language": "python",
      "name": "tws"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Exercise 3. Text Representation....ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lupis30puc/bipm_text_analytics_exercises/blob/main/Exercise_3_Text_Representation_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG1MNz1MrnJ2"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import TfidfModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INyZF7O3rnJ5"
      },
      "source": [
        "### 2. Load stemmed dataset from exercise 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svvbH0KRrnJ6"
      },
      "source": [
        "stem_corpus = pickle.load(open('stem_corpus.pkl','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXIxdQxOrnJ8",
        "outputId": "dd15bc4e-68af-46d4-af6e-d6530b5f022e"
      },
      "source": [
        "stem_corpus.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>car wonder enlighten car saw dai door sport ca...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clock poll final final clock report acceler cl...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>question folk mac plu final gave ghost weekend...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>weitek nntppostinghost amber ssd csd harri com...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shuttl launch question articl cowcb world std ...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  target  \\\n",
              "0  car wonder enlighten car saw dai door sport ca...       7   \n",
              "1  clock poll final final clock report acceler cl...       4   \n",
              "2  question folk mac plu final gave ghost weekend...       4   \n",
              "3  weitek nntppostinghost amber ssd csd harri com...       1   \n",
              "4  shuttl launch question articl cowcb world std ...      14   \n",
              "\n",
              "            target_names  \n",
              "0              rec.autos  \n",
              "1  comp.sys.mac.hardware  \n",
              "2  comp.sys.mac.hardware  \n",
              "3          comp.graphics  \n",
              "4              sci.space  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyaMcWEwrnJ-"
      },
      "source": [
        "corpus = stem_corpus.content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4imTecWnrnKA",
        "outputId": "c3cd144a-5bd3-4641-872f-927d7019e50e"
      },
      "source": [
        "corpus[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'car wonder enlighten car saw dai door sport car look late earli call bricklin door small addit bumper separ rest bodi know tellm model engin spec year product car histori info funki look car email thank brought neighborhood lerxst'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3V8In4wrnKC",
        "outputId": "dc973924-99af-448b-e5c2-4be9b70add97"
      },
      "source": [
        "stem_corpus.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 11314 entries, 0 to 11313\n",
            "Data columns (total 3 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   content       11314 non-null  object\n",
            " 1   target        11314 non-null  int64 \n",
            " 2   target_names  11314 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 673.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU5bpWiIrnKE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCNpm39VrnKG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "belUNSfGrnKI"
      },
      "source": [
        "## 3. Bag-of-words (sklearn):\n",
        "### a. Apply the following transformations to the stemmed data using the fit_transform() function. \n",
        "What is each of them doing? \n",
        "What are the pros and cons of each approach?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO0JSo9rrnKI"
      },
      "source": [
        "approach_1 = CountVectorizer(max_df=0.95, min_df=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZm3qVM6rnKK"
      },
      "source": [
        "transform_1 = approach_1.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4kZWfZhrnKM",
        "outputId": "f30b6f4f-7888-4bad-d31b-ee5559596f5e"
      },
      "source": [
        "print(transform_1[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 29)\t5\n",
            "  (0, 225)\t1\n",
            "  (0, 49)\t1\n",
            "  (0, 123)\t2\n",
            "  (0, 28)\t1\n",
            "  (0, 186)\t1\n",
            "  (0, 110)\t1\n",
            "  (0, 61)\t1\n",
            "  (0, 234)\t1\n",
            "  (0, 100)\t1\n",
            "  (0, 59)\t1\n",
            "  (0, 203)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R1S7_4PrnKP"
      },
      "source": [
        "approach_2 = TfidfVectorizer(max_df=0.95, min_df=0.05,use_idf=False, norm='l1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fxEvL-qrnKR"
      },
      "source": [
        "transform_2 = approach_2.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc09jSAgrnKS",
        "outputId": "595ed26c-9430-469b-ca5f-24fd13538173"
      },
      "source": [
        "print(transform_2[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 29)\t0.29411764705882354\n",
            "  (0, 225)\t0.058823529411764705\n",
            "  (0, 49)\t0.058823529411764705\n",
            "  (0, 123)\t0.11764705882352941\n",
            "  (0, 28)\t0.058823529411764705\n",
            "  (0, 186)\t0.058823529411764705\n",
            "  (0, 110)\t0.058823529411764705\n",
            "  (0, 61)\t0.058823529411764705\n",
            "  (0, 234)\t0.058823529411764705\n",
            "  (0, 100)\t0.058823529411764705\n",
            "  (0, 59)\t0.058823529411764705\n",
            "  (0, 203)\t0.058823529411764705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1hcrD_crnKU"
      },
      "source": [
        "approach_3 = TfidfVectorizer(max_df=0.95, min_df=0.05, smooth_idf=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqZr5iz8rnKW"
      },
      "source": [
        "transform_3 = approach_3.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEi33oqJrnKX",
        "outputId": "c1172f66-2bb5-4a51-8e10-379d96bff944"
      },
      "source": [
        "print(transform_3[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 203)\t0.121682990038635\n",
            "  (0, 59)\t0.13619718354871735\n",
            "  (0, 100)\t0.17360510673829524\n",
            "  (0, 234)\t0.12205830867257342\n",
            "  (0, 61)\t0.17175464030050264\n",
            "  (0, 110)\t0.09716570435591144\n",
            "  (0, 186)\t0.1771717303583916\n",
            "  (0, 28)\t0.1510033429609071\n",
            "  (0, 123)\t0.23634859995373567\n",
            "  (0, 49)\t0.1407339623887973\n",
            "  (0, 225)\t0.16984862582327953\n",
            "  (0, 29)\t0.8508576182722584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUZrmqk1rnKZ"
      },
      "source": [
        "How many features are left in the dictionary in iii. and what are their names (Hint: Use get_feature_names())? \n",
        "\n",
        "Do the features make sense? Are they different to those in i. and ii.? \n",
        "\n",
        "What happens if you change max_df and min_df?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yev2CpaQrnKa",
        "outputId": "cd8524a8-bc1c-4836-8a5c-44a0e82fd957"
      },
      "source": [
        "len(approach_1.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNEu2W3_rnKb"
      },
      "source": [
        "#approach_1.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Uz6PUOrnKd",
        "outputId": "d4ef0c28-6da5-4bd8-9105-f2d4c80c4d15"
      },
      "source": [
        "len(approach_2.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N6HYHftrnKf"
      },
      "source": [
        "#approach_2.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VDoo-inrnKh",
        "outputId": "686cb22f-8484-4b65-ac64-9bdb01b7633b"
      },
      "source": [
        "len(approach_3.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VINZDCjkrnKj"
      },
      "source": [
        "### b. Apply Binarizer() to the result from a. i. using again fit_transform(). \n",
        "What does the result stand for? What are its pros and cons?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSlMHbI8rnKj"
      },
      "source": [
        "#como se hace???"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn9ZocodrnKl"
      },
      "source": [
        "approach_1 = Binarizer(approach_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWDUJHPQrnKm",
        "outputId": "b7a21982-e980-4a81-b80a-e1c42c209b77"
      },
      "source": [
        "approach_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Binarizer(copy=True,\n",
              "          threshold=CountVectorizer(analyzer='word', binary=False,\n",
              "                                    decode_error='strict',\n",
              "                                    dtype=<class 'numpy.int64'>,\n",
              "                                    encoding='utf-8', input='content',\n",
              "                                    lowercase=True, max_df=0.95,\n",
              "                                    max_features=None, min_df=0.05,\n",
              "                                    ngram_range=(1, 1), preprocessor=None,\n",
              "                                    stop_words=None, strip_accents=None,\n",
              "                                    token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                    tokenizer=None, vocabulary=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zofPHsAKrnKp"
      },
      "source": [
        "transform_a1 = Binarizer(approach_1.fit_transform(stem_corpus.content))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH63XLWzrnKq",
        "outputId": "38870c79-b8e8-4496-d3d2-87f3083f9e63"
      },
      "source": [
        "print(stem_1b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binarizer(copy=True,\n",
            "          threshold=<11314x235 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 250758 stored elements in Compressed Sparse Row format>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOuXXMTBrnKs"
      },
      "source": [
        "#print(stem_1 == stem_1b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlJRjyfnrnKt"
      },
      "source": [
        "### c. Put the frequencies for the first document from a. and b. in a data frame with a column keys containing the feature names from a. and four additional columns with the corresponding frequencies from a. and b. (Hint: Convert the corpus to an array first.).  Keep only those rows of the data frame with keys representing words that exist in the first document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaddzv-ZrnKt"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "vect = TfidfVectorizer()\n",
        "tfidf_matrix = vect.fit_transform(documents)\n",
        "df = pd.DataFrame(tfidf_matrix.toarray(), columns = vect.get_feature_names())\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHEvJKykrnKv"
      },
      "source": [
        "keys = approach_1.get_feature_names()\n",
        "df = pd.DataFrame(transform_1.toarray(), columns = keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJ9IaoYrnKx",
        "outputId": "c68c359f-7300-4106-8199-00d69662b37a"
      },
      "source": [
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   abl  accept  access  actual  address  advanc  ago  agre  allow  answer  \\\n",
            "0    0       0       0       0        0       0    0     0      0       0   \n",
            "1    0       0       0       0        0       0    0     0      0       1   \n",
            "2    0       0       1       1        0       1    0     0      0       1   \n",
            "3    0       0       0       0        1       0    0     0      0       0   \n",
            "4    0       0       0       0        0       0    0     0      0       0   \n",
            "\n",
            "   ...  wonder  word  work  world  write  wrong  wrote  xnewsread  ye  year  \n",
            "0  ...       1     0     0      0      0      0      0          0   0     1  \n",
            "1  ...       0     0     0      0      0      0      0          0   0     0  \n",
            "2  ...       1     0     0      0      0      0      0          0   0     0  \n",
            "3  ...       0     0     0      0      1      0      1          1   0     0  \n",
            "4  ...       1     0     0      2      1      0      0          0   1     0  \n",
            "\n",
            "[5 rows x 235 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYAhWk9IrnKz"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsiUjBJzrnK1"
      },
      "source": [
        "corpus_array = np.array(stem_corpus.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-zRDVGmrnK2"
      },
      "source": [
        "corpus_array[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fxdLSrwrnK4"
      },
      "source": [
        "### d. Sort the data frame (descending) on:\n",
        "####         i. TF-IDF Frequencies\n",
        "####         ii. Absolute Frequencies\n",
        "Do you see differences? Why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkPIpdYXrnK5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_7IusjsrnK6"
      },
      "source": [
        "## 4. Bag-of-words (gensim):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2wNmsjPrnK6"
      },
      "source": [
        "### a. Create a corpus as input for gensim with corpus_gen=[doc.split() for doc in data_stem]. What is this command exactly doing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNUpQB_drnK6"
      },
      "source": [
        "corpus_gen=[doc.split() for doc in stem_corpus.content]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QudQgJv0rnK8",
        "outputId": "d2cc159c-c901-4efc-b4c5-2d32a52b8493"
      },
      "source": [
        "corpus_gen[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['car',\n",
              " 'wonder',\n",
              " 'enlighten',\n",
              " 'car',\n",
              " 'saw',\n",
              " 'dai',\n",
              " 'door',\n",
              " 'sport',\n",
              " 'car',\n",
              " 'look',\n",
              " 'late',\n",
              " 'earli',\n",
              " 'call',\n",
              " 'bricklin',\n",
              " 'door',\n",
              " 'small',\n",
              " 'addit',\n",
              " 'bumper',\n",
              " 'separ',\n",
              " 'rest',\n",
              " 'bodi',\n",
              " 'know',\n",
              " 'tellm',\n",
              " 'model',\n",
              " 'engin',\n",
              " 'spec',\n",
              " 'year',\n",
              " 'product',\n",
              " 'car',\n",
              " 'histori',\n",
              " 'info',\n",
              " 'funki',\n",
              " 'look',\n",
              " 'car',\n",
              " 'email',\n",
              " 'thank',\n",
              " 'brought',\n",
              " 'neighborhood',\n",
              " 'lerxst']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ng1LE2RrnK9"
      },
      "source": [
        "### b. Create a gensim Dictionary() based on the corpus. Call it id2word. Apply to it id2word.filter_extremes(no_below=566, no_above=0.95). What is this method doing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9DWdDtarnK-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}