{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise5-text classification-team5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lupis30puc/bipm_text_analytics_exercises/blob/main/Exercise5_text_classification_team5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iykvtvV74D7r"
      },
      "source": [
        "In this exercise we will build a classification model for the newsgroup dataset. We will apply the following steps:\n",
        "> A. Document representation with tf-idf\n",
        "\n",
        ">B. Naïve Bayes classification model\n",
        "\n",
        ">C. Pipelines and Random Forest\n",
        "\n",
        ">D. Grid search with tf-idf\n",
        "\n",
        ">E. Grid search with Doc2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxnkXXVqZkh_"
      },
      "source": [
        "1. Import the following packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgWrtEnsUmkY"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajO0XWAPZ6ZX"
      },
      "source": [
        "2. Load the stemmed data from Exercise 2 together with the columns target and target_names. What are the classes here? What is their distribution?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4epQ-Ikckav",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "44142e13-8677-460d-b540-27a8a8f425f3"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cb2fbc57-bb45-4786-80b4-0710bb936d76\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cb2fbc57-bb45-4786-80b4-0710bb936d76\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Stemmed.pkl to Stemmed.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPyQvUFKcwdn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "27b38815-2097-46e3-b449-7aede4fbe05c"
      },
      "source": [
        "#Loading the stemmed data\n",
        "stemmed = pickle.load(open('Stemmed.pkl','rb'))\n",
        "stemmed[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'car wonder enlighten car saw dai door sport car look late earli call bricklin door small addit bumper separ rest bodi know tellm model engin spec year product car histori info funki look car mail thank'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz3fEJjcdFJF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b289c7a0-3f99-4688-dfd3-e84e6ba1b9c4"
      },
      "source": [
        "#Loading the original dara\n",
        "original=pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "print(original.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             content  ...           target_names\n",
            "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...              rec.autos\n",
            "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...  comp.sys.mac.hardware\n",
            "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...  comp.sys.mac.hardware\n",
            "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...          comp.graphics\n",
            "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...              sci.space\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU3ZKgJCdwSn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3ad9350a-96a3-4c05-e574-9b3cb8699aea"
      },
      "source": [
        "df = pd.DataFrame(columns=['preprocessed', 'target', 'target_names']) # creating new DF\n",
        "df['preprocessed']=stemmed # getting the preprocessed data\n",
        "df['target']=original['target'] # getting the orignal target number\n",
        "df['target_names']=original['target_names'] # getting the original target names\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preprocessed</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>car wonder enlighten car saw dai door sport ca...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clock poll final final clock report acceler cl...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>question folk mac plu final gave ghost weekend...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>weitek robert kyanko rob rjck uucp wrote abrax...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shuttl launch question articl cowcb world std ...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        preprocessed  ...           target_names\n",
              "0  car wonder enlighten car saw dai door sport ca...  ...              rec.autos\n",
              "1  clock poll final final clock report acceler cl...  ...  comp.sys.mac.hardware\n",
              "2  question folk mac plu final gave ghost weekend...  ...  comp.sys.mac.hardware\n",
              "3  weitek robert kyanko rob rjck uucp wrote abrax...  ...          comp.graphics\n",
              "4  shuttl launch question articl cowcb world std ...  ...              sci.space\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyLND89SZ_1f"
      },
      "source": [
        "3. Restrict the dataset from 2. to the following topics: *'soc.religion.christian', 'rec.sport.hockey', 'talk.politics.mideast', 'rec.motorcycles’*. Remove the ‘contents’ column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHEjwTgptJrG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d8ad2630-33d9-45ce-8267-c8a1bd7e773d"
      },
      "source": [
        "targetsnames =  ['talk.politics.mideast', 'rec.sport.hockey' , 'soc.religion.christian', 'rec.motorcycles'] # relevant topics\n",
        "df.target_names.isin(targetsnames) # creating boolean which shoes if target is relvant or not\n",
        "df_2=df[df.target_names.isin(targetsnames)]  # building a new DF with just the relevant topics\n",
        "df_2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preprocessed</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>recommend duc worth ducati gt line ducati gt m...</td>\n",
              "      <td>8</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>nhl team captain articl apr samba oit unc edu ...</td>\n",
              "      <td>10</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>pantheism environment articl apr atho rutger e...</td>\n",
              "      <td>15</td>\n",
              "      <td>soc.religion.christian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>isra expans lust articl spam math adelaid edu ...</td>\n",
              "      <td>17</td>\n",
              "      <td>talk.politics.mideast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>goali mask articl netnew upenn edu kkeller mai...</td>\n",
              "      <td>10</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         preprocessed  ...            target_names\n",
              "10  recommend duc worth ducati gt line ducati gt m...  ...         rec.motorcycles\n",
              "21  nhl team captain articl apr samba oit unc edu ...  ...        rec.sport.hockey\n",
              "28  pantheism environment articl apr atho rutger e...  ...  soc.religion.christian\n",
              "33  isra expans lust articl spam math adelaid edu ...  ...   talk.politics.mideast\n",
              "35  goali mask articl netnew upenn edu kkeller mai...  ...        rec.sport.hockey\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dnx078saEk8"
      },
      "source": [
        "## Part A: Document representation with tf-idf\n",
        "4. Apply the following function to df:\n",
        "  \n",
        "  *docs_train, docs_test, y_train, y_test =train_test_split(df.preprocessed, df.target, test_size = 0.20, random_state = 12)*\n",
        "\n",
        "  What is it doing and why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oMC6jTitXhl"
      },
      "source": [
        "docs_train, docs_test, y_train, y_test =train_test_split(df_2.preprocessed, df_2.target, test_size = 0.20, random_state = 12) \n",
        "# is splliting the data we have in test and training data so we can measure the accuracy of out model later on"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km_wCDjntYgv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "bc914319-72c1-4677-ae00-8c49bc90eea9"
      },
      "source": [
        "print(docs_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9319     washington beat pitt articl kkq acsu buffalo e...\n",
            "7883     latest branch davidian articl apr geneva rutge...\n",
            "6290     qualiti cathol liturgi tim rolf write activ pa...\n",
            "947      tuff christian realiz frequent get troubl stra...\n",
            "11242    abc canada abc coverag king flame game suppos ...\n",
            "                               ...                        \n",
            "7699     chant passion mike rolf write know latin beaut...\n",
            "2169     playoff predict predict try laugh hyster someb...\n",
            "764      seventh centuri armenian math problem problem ...\n",
            "8139     stan fischler keenan stuff articl apr new colu...\n",
            "3269     ship bike recommend ship motorcycl san francis...\n",
            "Name: preprocessed, Length: 473, dtype: object 9319     10\n",
            "7883     15\n",
            "6290     15\n",
            "947      15\n",
            "11242    10\n",
            "         ..\n",
            "7699     15\n",
            "2169     10\n",
            "764      17\n",
            "8139     10\n",
            "3269      8\n",
            "Name: target, Length: 473, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDRRYB3haOcS"
      },
      "source": [
        "5. Derive the tf-idf frequency matrix for docs_train using\n",
        "  \n",
        "  *TfidfVectorizer and max_df=0.7, min_df=0.1*. \n",
        "Store in tf_train. \n",
        "\n",
        "  Apply the trained transformer to the test data using transform(). Store in tf_test. \n",
        "\n",
        "  Why are we not using fit_transform on the test data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH3882IqvC3v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "eb27b0ad-1510-46e4-f0cb-30fa8748b1a1"
      },
      "source": [
        "model = TfidfVectorizer(max_df=0.7, min_df=0.1)\n",
        "tf_train = model.fit_transform(docs_train)\n",
        "print(\"train\" '\\n', tf_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "   (0, 17)\t0.1390466118001983\n",
            "  (0, 53)\t0.09817941673585602\n",
            "  (0, 71)\t0.13435314501375176\n",
            "  (0, 39)\t0.19287904798535266\n",
            "  (0, 11)\t0.14806750809457395\n",
            "  (0, 70)\t0.1265014336483417\n",
            "  (0, 35)\t0.1466956012087497\n",
            "  (0, 68)\t0.1490057688850429\n",
            "  (0, 75)\t0.11882822042574444\n",
            "  (0, 87)\t0.12263461795633522\n",
            "  (0, 84)\t0.3285367160772088\n",
            "  (0, 67)\t0.12452675151019846\n",
            "  (0, 8)\t0.14322830236191653\n",
            "  (0, 57)\t0.24687173660005488\n",
            "  (0, 90)\t0.10833888239946689\n",
            "  (0, 29)\t0.22645324664826336\n",
            "  (0, 22)\t0.14199360411972675\n",
            "  (0, 47)\t0.29567190047239905\n",
            "  (0, 6)\t0.5885931984293965\n",
            "  (0, 19)\t0.14079168938068798\n",
            "  (0, 66)\t0.12766974268609335\n",
            "  (0, 12)\t0.10220960874887552\n",
            "  (0, 89)\t0.06672396194008437\n",
            "  (0, 0)\t0.09533980685475581\n",
            "  (0, 1)\t0.15135163664161153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YqlN4O86DlI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "f6653397-4c63-4ee9-d4d9-8eedd775af5b"
      },
      "source": [
        "tf_test = model.transform(docs_test)\n",
        "print(\"test\" '\\n', tf_test[0])\n",
        "print(\"feature names\" '\\n',  model.get_feature_names())\n",
        "\n",
        "#fit_transform(self, raw_documents[, y]) --Learn vocabulary and idf, return document-term matrix.\n",
        "#transform(self, raw_documents[, copy]) --Transform documents to document-term matrix.\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test\n",
            "   (0, 90)\t0.4218419068406405\n",
            "  (0, 89)\t0.25980481534768\n",
            "  (0, 76)\t0.18366113234773754\n",
            "  (0, 73)\t0.2629127316250822\n",
            "  (0, 71)\t0.26156715681108517\n",
            "  (0, 52)\t0.266017557369826\n",
            "  (0, 42)\t0.17537403770957705\n",
            "  (0, 24)\t0.26636938793032844\n",
            "  (0, 18)\t0.29520972341240415\n",
            "  (0, 14)\t0.27844065967624904\n",
            "  (0, 13)\t0.23134225672574707\n",
            "  (0, 2)\t0.26707729083953\n",
            "  (0, 1)\t0.2946608899330096\n",
            "  (0, 0)\t0.18561353519014362\n",
            "feature names\n",
            " ['apr', 'articl', 'ask', 'awai', 'believ', 'best', 'better', 'bike', 'call', 'case', 'christian', 'claim', 'com', 'come', 'cours', 'dai', 'differ', 'dod', 'edu', 'end', 'exist', 'fact', 'far', 'follow', 'game', 'gener', 'get', 'go', 'god', 'good', 'got', 'great', 'happen', 'help', 'hockei', 'includ', 'interest', 'israel', 'kill', 'know', 'let', 'life', 'like', 'littl', 'live', 'long', 'look', 'lot', 'make', 'mean', 'need', 'new', 'opinion', 'peopl', 'person', 'place', 'plai', 'point', 'post', 'probabl', 'problem', 'question', 'read', 'reason', 'right', 'rutger', 'sai', 'said', 'second', 'start', 'state', 'sure', 'talk', 'team', 'tell', 'thing', 'think', 'thought', 'time', 'todai', 'true', 'try', 'univers', 'us', 'wai', 'want', 'word', 'work', 'world', 'write', 'year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EG0lY7P5jzM"
      },
      "source": [
        "We don't use fit_transform with test data because we will use it to classify the topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHZhwaH9aUGf"
      },
      "source": [
        "## Part B: Naïve Bayes classification model\n",
        "6. Run the following two lines. What are they doing?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUJ0_SL2w5Q8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7398737-5587-4b5e-fead-3678886dd5a0"
      },
      "source": [
        "clf =MultinomialNB() #initialize the Naive Bayes classifier for multinomial models\n",
        "clf.fit(tf_train,y_train) #Fit Naive Bayes classifier according to X, y \n",
        "#--X:Training vectors, where n_samples is the number of samples and n_features is the number of features.\n",
        "#--y:Target values.\n",
        "\n",
        "#The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). \n",
        "#The multinomial distribution normally requires integer feature counts. \n",
        "#However, in practice, fractional counts such as tf-idf may also work."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCd81sFFapyU"
      },
      "source": [
        "7. Run *y_pred = clf.predict(tf_test)*. What is it doing?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRwUvNpQvanf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "069fe962-9a52-4267-fe57-44064c90f99a"
      },
      "source": [
        "y_pred = clf.predict(tf_test) #Perform classification on an array of test vectors X.\n",
        "print(len(y_pred))\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "473\n",
            "[10 15 17 15 10 15 10 10  8  8 15 15 17 15 15 10  8 10 10 10 15 15  8  8\n",
            " 15  8 17 10 17 10 15 15 17 15  8  8 17  8  8  8  8 17 10 15 17 15 10 17\n",
            " 17 15 17 17 10 10 10 10 17  8 15  8  8 10 17 17  8 15 17 15 10  8 17 10\n",
            " 15  8 15 10 15  8 17 10 10  8 10 10 17  8  8  8 10  8 10 10 17 10 17 15\n",
            " 15 15  8 17 15 17 15 15 17  8  8 15  8 10 10 15 17 15  8 10 17  8 15 15\n",
            " 17 17  8 10  8 17  8 10  8  8  8 10 15 17  8 17 17 17 15  8 17  8 10 15\n",
            "  8  8  8  8  8  8  8 15 10 10 17 17 10 10  8 10  8 17 10 17 10 10 15 10\n",
            "  8 15 15 15  8  8  8 10  8 15 17 15  8 10 10 17  8  8 15 17 17 17  8 17\n",
            "  8 17 17  8  8  8 15  8  8 10 10 17  8  8 15 10 15 10 17  8 10 15 15 17\n",
            "  8  8 15  8 15 15  8 15  8  8 10 10  8 17  8  8 17  8 15 15 15  8 10 17\n",
            " 17  8 17 10  8 15 15 17  8 17 10 10 15 17  8  8  8 10  8  8  8 15 17 10\n",
            "  8  8  8 15 15 17 15  8 17 17 17 15 15 15 17 10 15 17  8 10 15 10 10 15\n",
            "  8 17 15 10  8 17 10  8 15 15 17 17 10  8 15 10 15 17  8 10 10 15  8  8\n",
            " 15  8 15  8 10  8  8 10  8  8 15 10 15 17 10 15 15 10 15 15 15 17 10 10\n",
            " 10 15 10 15  8 10 10  8  8  8 10 10 10 10 17 17  8 17  8 15 17  8 15 10\n",
            "  8 17 17 10 10 15  8 17 10 17 17 15 15 10 17  8  8 10  8  8  8 15  8  8\n",
            "  8 10 10  8 15 10  8 15  8 10 15  8 15  8 17 15 10 17 17 10  8  8 10  8\n",
            " 15 10 17 17 10 17  8 15 17 10 10 15 15 10  8 15 15 15  8 17  8 10 10 15\n",
            " 17 10 10 17  8 17 17 10 10 17 10 15 15 17 17  8 10 15 15 17 15 15  8 15\n",
            "  8 15 15 10  8 10 17 10  8  8 10 15 17 10 15 10  8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oilQjmwzaty9"
      },
      "source": [
        "8. Determine clf.score(tf_train ,y_train), accuracy_score(y_test, y_pred) and classification_report(y_test, y_pred). What do they say about the model? Is it a good one?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7E6bIQAvT8X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be2cea66-258c-4176-a36c-79b3374bfefa"
      },
      "source": [
        "score_1 = clf.score(tf_train ,y_train) # Return the mean accuracy on the given test data and labels. (X, y)\n",
        "print(score_1)\n",
        "# In multi-label classification, this is the subset accuracy \n",
        "# which is a harsh metric since you require for each sample that each label set be correctly predicted.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.871822033898305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv2rXN0GwDje",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fcc672e-a9da-4731-b645-3d42bd5f7624"
      },
      "source": [
        "acc_1 =accuracy_score(y_test, y_pred) # Accuracy classification score. (y_true, y_pred)\n",
        "print(acc_1)\n",
        "# In multilabel classification, this function computes subset accuracy: \n",
        "# the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8393234672304439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3wbvulQwF-5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "37193d8a-5190-4f5a-a55f-e776cb1e6baf"
      },
      "source": [
        "report_1 = classification_report(y_test, y_pred) # Build a text report showing the main classification metrics. (y_true, y_pred)\n",
        "print(report_1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           8       0.82      0.87      0.84       134\n",
            "          10       0.90      0.89      0.89       118\n",
            "          15       0.79      0.87      0.83       106\n",
            "          17       0.85      0.73      0.79       115\n",
            "\n",
            "    accuracy                           0.84       473\n",
            "   macro avg       0.84      0.84      0.84       473\n",
            "weighted avg       0.84      0.84      0.84       473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1ldCRml6rTD"
      },
      "source": [
        "**If you look at class 15 (under estimation) and 17 (more over estimation)...**\n",
        "\n",
        "**Generally a good model, especially if you think about the simple approach.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_YsJ55AbXgS"
      },
      "source": [
        "## Part C: Pipelines and Random Forest\n",
        "9. Apply the following two lines. What are they doing? How does the resulting model look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lRJFNZlvXBd"
      },
      "source": [
        "# Pipeline of transforms with a final estimator.\n",
        "rf = Pipeline([('tfidf', TfidfVectorizer(max_df=0.7, min_df=0.1)), ('clf', RandomForestClassifier(random_state = 42)),])\n",
        "# The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQuBTFplZ18h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "85c68c53-036e-4642-8c40-f998ace980a4"
      },
      "source": [
        "# Fit all the transforms one after the other and transform the data, then fit the transformed data using the final estimator.\n",
        "rf.fit(docs_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=0.7, max_features=None,\n",
              "                                 min_df=0.1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=42,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNUOiH-Zbq5I"
      },
      "source": [
        "10. Determine the performance of the model in 9. Is it better than the Naïve Bayes one?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJxtz-cBy7UR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2130876-593a-434d-aa2f-b01b02c91bb8"
      },
      "source": [
        "score_2 = rf.score(docs_train, y_train) # Apply transforms, and score with the final estimator\n",
        "print(score_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9936440677966102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKLCf86Nzx17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a6d6928-0979-4150-ef06-4752a2a81cd0"
      },
      "source": [
        "rf_y_pred = rf.predict(docs_test)\n",
        "# Apply transforms to the data, and predict with the final estimator\n",
        "print(len(rf_y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32ImS1vIavCn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7964ccce-835b-4167-9b3e-cbbdc85403fe"
      },
      "source": [
        "acc_2 = accuracy_score(y_test, rf_y_pred)\n",
        "print(acc_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8668076109936576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXINkr_N8qjk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ddeb0bfc-62e4-416e-8e79-abd0e2142ad8"
      },
      "source": [
        "report_2 = classification_report(y_test, rf_y_pred)\n",
        "print(report_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           8       0.88      0.87      0.88       134\n",
            "          10       0.86      0.91      0.88       118\n",
            "          15       0.85      0.84      0.84       106\n",
            "          17       0.87      0.84      0.86       115\n",
            "\n",
            "    accuracy                           0.87       473\n",
            "   macro avg       0.87      0.87      0.87       473\n",
            "weighted avg       0.87      0.87      0.87       473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLal-t666Yo"
      },
      "source": [
        "Performs a bit better than Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL1cEzs6b1E-"
      },
      "source": [
        "## Part D: Grid search with tf-idf\n",
        "11. Run the following lines. What are they doing and why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st5WHaJ51DJC"
      },
      "source": [
        "param_grid = {'min_samples_leaf': [3, 4, 5], 'n_estimators': [10, 50, 100, 200, 300, 1000]}\n",
        "# The parameter grid to explore, as a dictionary mapping estimator parameters to sequences of allowed values."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UY75Wk41GU8"
      },
      "source": [
        "rf_2 = RandomForestClassifier(random_state = 42) # Initializing RandomForest Classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqXbFOMj1QMI"
      },
      "source": [
        "grid_search = GridSearchCV(estimator = rf_2, param_grid = param_grid, cv = 10)\n",
        "# Exhaustive search over specified parameter values for an estimator.\n",
        "# The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebI7Wgly1a4H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6b05bd77-805a-4143-990c-189a691139df"
      },
      "source": [
        "grid_search.fit(tf_train, y_train) # Run fit with all sets of parameters."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=42,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'min_samples_leaf': [3, 4, 5],\n",
              "                         'n_estimators': [10, 50, 100, 200, 300, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtoeP10jcIZz"
      },
      "source": [
        "12. What is the best model (Hint: grid_search.best_params_) in 11?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y88Lzay2-KA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0422d8c6-cd25-4b9f-ade3-080d67d443bc"
      },
      "source": [
        "best_model = grid_search.best_params_  # Parameter setting that gave the best results on the hold out data.\n",
        "print(best_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'min_samples_leaf': 4, 'n_estimators': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxVLPVKlcQtB"
      },
      "source": [
        "13. Determine the performance of the best model in 12 and compare it with the performance in 10 (Hint: Access the model with grid_search.best_estimator_)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l6v2fmd3PBX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f845e6b-72aa-48be-e851-ca45189b93be"
      },
      "source": [
        "random_f = grid_search.best_estimator_  # Estimator that was chosen by the search, i.e. estimator which gave highest score (or smallest loss if specified) on the left out data. Not available if refit=False.\n",
        "y_pred_3 = random_f.predict(tf_test)\n",
        "score_3 = grid_search.score(tf_train, y_train)\n",
        "print(score_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9533898305084746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ6vLNMhBvNe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4a84677-7ea8-4109-ce72-87ef88a6a531"
      },
      "source": [
        "acc_3 = accuracy_score(y_test, y_pred_3)\n",
        "print(acc_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8731501057082452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1BISGr8DtmF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0dc45338-debc-49ee-8613-3e9a9e53d26c"
      },
      "source": [
        "report_3 = classification_report(y_test, y_pred_3)\n",
        "print(report_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           8       0.94      0.87      0.90       134\n",
            "          10       0.85      0.93      0.89       118\n",
            "          15       0.85      0.82      0.84       106\n",
            "          17       0.85      0.87      0.86       115\n",
            "\n",
            "    accuracy                           0.87       473\n",
            "   macro avg       0.87      0.87      0.87       473\n",
            "weighted avg       0.88      0.87      0.87       473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Dqsx9F4vsr"
      },
      "source": [
        "**The best model comparing 11, Naives and 10 is still 10.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLyzO58mcWG5"
      },
      "source": [
        "## Part E: Grid search with Doc2Vec\n",
        "14. Derive the text representation of the dataset from 3. with the Doc2vec model (vector_size=100, min_count=566). Make sure that you consider the train/test split. Then apply the same approach as in 11. to 13. Are the results better than in 13.?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQHrpDNMcNQe"
      },
      "source": [
        "#Prepare dataset\n",
        "corpus_gen = [doc.split() for doc in df_2.preprocessed]\n",
        "docs2_train, docs2_test, y_train_2, y_test_2 =train_test_split(corpus_gen, df_2.target, test_size = 0.20, random_state = 12) \n",
        "\n",
        "documents_train = [TaggedDocument(doc, [i]) for i, doc in enumerate(docs2_train)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiPc0SK_7ymy"
      },
      "source": [
        "# Run doc2vec on tagged texts\n",
        "model2 = Doc2Vec(documents_train, vector_size=100, min_count=566)\n",
        "\n",
        "data_train = pd.DataFrame([model2.infer_vector(doc) for doc in docs2_train])\n",
        "data_test = pd.DataFrame([model2.infer_vector(doc) for doc in docs_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA9k7qib8Vft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "1a05ee26-b153-4c08-f9c0-3f669ac9674b"
      },
      "source": [
        "data_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.007446</td>\n",
              "      <td>-0.000986</td>\n",
              "      <td>-0.010638</td>\n",
              "      <td>0.011423</td>\n",
              "      <td>-0.000872</td>\n",
              "      <td>0.004708</td>\n",
              "      <td>-0.004648</td>\n",
              "      <td>-0.000894</td>\n",
              "      <td>-0.001165</td>\n",
              "      <td>-0.002955</td>\n",
              "      <td>0.003636</td>\n",
              "      <td>0.001516</td>\n",
              "      <td>0.009350</td>\n",
              "      <td>-0.002444</td>\n",
              "      <td>-0.002069</td>\n",
              "      <td>-0.011438</td>\n",
              "      <td>0.001573</td>\n",
              "      <td>0.013785</td>\n",
              "      <td>0.005954</td>\n",
              "      <td>0.006411</td>\n",
              "      <td>-0.013671</td>\n",
              "      <td>0.009582</td>\n",
              "      <td>0.003618</td>\n",
              "      <td>-0.005288</td>\n",
              "      <td>-0.005215</td>\n",
              "      <td>-0.001546</td>\n",
              "      <td>-0.007783</td>\n",
              "      <td>-0.009049</td>\n",
              "      <td>0.014987</td>\n",
              "      <td>0.001659</td>\n",
              "      <td>0.012572</td>\n",
              "      <td>-0.003872</td>\n",
              "      <td>0.004383</td>\n",
              "      <td>-0.015075</td>\n",
              "      <td>0.003393</td>\n",
              "      <td>-0.004249</td>\n",
              "      <td>-0.001048</td>\n",
              "      <td>-0.004095</td>\n",
              "      <td>0.004827</td>\n",
              "      <td>-0.009589</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007941</td>\n",
              "      <td>0.000431</td>\n",
              "      <td>-0.003274</td>\n",
              "      <td>0.016654</td>\n",
              "      <td>0.014790</td>\n",
              "      <td>0.017837</td>\n",
              "      <td>0.004124</td>\n",
              "      <td>0.000398</td>\n",
              "      <td>-0.016857</td>\n",
              "      <td>0.001292</td>\n",
              "      <td>0.007838</td>\n",
              "      <td>-0.021353</td>\n",
              "      <td>0.016556</td>\n",
              "      <td>1.209083e-02</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>0.009630</td>\n",
              "      <td>-0.003473</td>\n",
              "      <td>0.006290</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>0.010159</td>\n",
              "      <td>-0.009383</td>\n",
              "      <td>0.008710</td>\n",
              "      <td>-0.002220</td>\n",
              "      <td>0.006144</td>\n",
              "      <td>-0.008508</td>\n",
              "      <td>-0.005139</td>\n",
              "      <td>-0.005068</td>\n",
              "      <td>-0.013913</td>\n",
              "      <td>0.000797</td>\n",
              "      <td>-0.002434</td>\n",
              "      <td>0.002483</td>\n",
              "      <td>-0.000646</td>\n",
              "      <td>-0.001042</td>\n",
              "      <td>0.014663</td>\n",
              "      <td>0.003834</td>\n",
              "      <td>0.003764</td>\n",
              "      <td>-0.002463</td>\n",
              "      <td>0.009802</td>\n",
              "      <td>0.002558</td>\n",
              "      <td>-0.013692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.008682</td>\n",
              "      <td>-0.002034</td>\n",
              "      <td>-0.001568</td>\n",
              "      <td>0.022848</td>\n",
              "      <td>0.002711</td>\n",
              "      <td>0.014521</td>\n",
              "      <td>-0.014123</td>\n",
              "      <td>-0.011882</td>\n",
              "      <td>-0.002656</td>\n",
              "      <td>-0.010413</td>\n",
              "      <td>0.015991</td>\n",
              "      <td>0.008217</td>\n",
              "      <td>0.009964</td>\n",
              "      <td>-0.017364</td>\n",
              "      <td>0.000651</td>\n",
              "      <td>-0.012127</td>\n",
              "      <td>0.016034</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>-0.002549</td>\n",
              "      <td>0.005676</td>\n",
              "      <td>-0.020371</td>\n",
              "      <td>-0.001052</td>\n",
              "      <td>0.005841</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.008876</td>\n",
              "      <td>0.001694</td>\n",
              "      <td>-0.019209</td>\n",
              "      <td>-0.012652</td>\n",
              "      <td>0.008708</td>\n",
              "      <td>-0.007820</td>\n",
              "      <td>-0.000457</td>\n",
              "      <td>0.004069</td>\n",
              "      <td>0.004547</td>\n",
              "      <td>-0.018393</td>\n",
              "      <td>-0.007978</td>\n",
              "      <td>0.015887</td>\n",
              "      <td>0.008990</td>\n",
              "      <td>0.002111</td>\n",
              "      <td>-0.007509</td>\n",
              "      <td>-0.013770</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.006662</td>\n",
              "      <td>0.010018</td>\n",
              "      <td>0.006550</td>\n",
              "      <td>0.023768</td>\n",
              "      <td>0.017730</td>\n",
              "      <td>0.023151</td>\n",
              "      <td>0.016392</td>\n",
              "      <td>0.008507</td>\n",
              "      <td>-0.002510</td>\n",
              "      <td>0.001345</td>\n",
              "      <td>0.000872</td>\n",
              "      <td>-0.020125</td>\n",
              "      <td>0.014458</td>\n",
              "      <td>9.351380e-03</td>\n",
              "      <td>0.007274</td>\n",
              "      <td>0.006856</td>\n",
              "      <td>-0.002791</td>\n",
              "      <td>0.012659</td>\n",
              "      <td>-0.004890</td>\n",
              "      <td>0.023065</td>\n",
              "      <td>0.005345</td>\n",
              "      <td>0.010861</td>\n",
              "      <td>-0.003609</td>\n",
              "      <td>0.022151</td>\n",
              "      <td>-0.005048</td>\n",
              "      <td>-0.003544</td>\n",
              "      <td>0.000788</td>\n",
              "      <td>-0.013396</td>\n",
              "      <td>0.010217</td>\n",
              "      <td>0.001329</td>\n",
              "      <td>0.020461</td>\n",
              "      <td>-0.010438</td>\n",
              "      <td>0.002425</td>\n",
              "      <td>0.023387</td>\n",
              "      <td>0.006402</td>\n",
              "      <td>-0.007602</td>\n",
              "      <td>0.002157</td>\n",
              "      <td>0.010048</td>\n",
              "      <td>0.008154</td>\n",
              "      <td>-0.023768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.008094</td>\n",
              "      <td>-0.006639</td>\n",
              "      <td>-0.008165</td>\n",
              "      <td>0.016391</td>\n",
              "      <td>-0.008243</td>\n",
              "      <td>0.005007</td>\n",
              "      <td>0.005787</td>\n",
              "      <td>-0.006307</td>\n",
              "      <td>0.012727</td>\n",
              "      <td>-0.004804</td>\n",
              "      <td>0.022919</td>\n",
              "      <td>0.008962</td>\n",
              "      <td>0.000350</td>\n",
              "      <td>-0.009479</td>\n",
              "      <td>-0.010033</td>\n",
              "      <td>0.002994</td>\n",
              "      <td>0.015209</td>\n",
              "      <td>0.005381</td>\n",
              "      <td>0.007153</td>\n",
              "      <td>0.001536</td>\n",
              "      <td>-0.012903</td>\n",
              "      <td>0.007617</td>\n",
              "      <td>0.000676</td>\n",
              "      <td>-0.019338</td>\n",
              "      <td>0.008161</td>\n",
              "      <td>-0.002877</td>\n",
              "      <td>-0.021196</td>\n",
              "      <td>-0.010167</td>\n",
              "      <td>0.012425</td>\n",
              "      <td>-0.008161</td>\n",
              "      <td>-0.001147</td>\n",
              "      <td>-0.002437</td>\n",
              "      <td>0.006246</td>\n",
              "      <td>-0.007943</td>\n",
              "      <td>0.000821</td>\n",
              "      <td>0.009258</td>\n",
              "      <td>0.007975</td>\n",
              "      <td>0.006936</td>\n",
              "      <td>-0.009885</td>\n",
              "      <td>-0.003608</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004490</td>\n",
              "      <td>0.005919</td>\n",
              "      <td>-0.006164</td>\n",
              "      <td>0.023576</td>\n",
              "      <td>0.015403</td>\n",
              "      <td>0.019483</td>\n",
              "      <td>0.008129</td>\n",
              "      <td>0.017660</td>\n",
              "      <td>-0.008208</td>\n",
              "      <td>0.001216</td>\n",
              "      <td>-0.004588</td>\n",
              "      <td>-0.017413</td>\n",
              "      <td>0.023873</td>\n",
              "      <td>5.426322e-03</td>\n",
              "      <td>0.010927</td>\n",
              "      <td>0.001780</td>\n",
              "      <td>-0.003710</td>\n",
              "      <td>0.008036</td>\n",
              "      <td>0.006753</td>\n",
              "      <td>0.024907</td>\n",
              "      <td>0.007795</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>0.001059</td>\n",
              "      <td>0.028608</td>\n",
              "      <td>-0.003812</td>\n",
              "      <td>-0.010329</td>\n",
              "      <td>0.004698</td>\n",
              "      <td>-0.014180</td>\n",
              "      <td>0.001750</td>\n",
              "      <td>-0.016257</td>\n",
              "      <td>0.010639</td>\n",
              "      <td>-0.007596</td>\n",
              "      <td>-0.004653</td>\n",
              "      <td>0.019195</td>\n",
              "      <td>-0.002375</td>\n",
              "      <td>-0.010197</td>\n",
              "      <td>-0.005115</td>\n",
              "      <td>0.007443</td>\n",
              "      <td>0.010493</td>\n",
              "      <td>-0.029363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.004603</td>\n",
              "      <td>-0.005152</td>\n",
              "      <td>-0.004259</td>\n",
              "      <td>0.009375</td>\n",
              "      <td>-0.003916</td>\n",
              "      <td>0.001466</td>\n",
              "      <td>0.004413</td>\n",
              "      <td>-0.000281</td>\n",
              "      <td>0.003976</td>\n",
              "      <td>-0.002836</td>\n",
              "      <td>0.002133</td>\n",
              "      <td>0.006059</td>\n",
              "      <td>0.001158</td>\n",
              "      <td>-0.004146</td>\n",
              "      <td>-0.010889</td>\n",
              "      <td>-0.000622</td>\n",
              "      <td>0.003436</td>\n",
              "      <td>0.002170</td>\n",
              "      <td>0.002650</td>\n",
              "      <td>-0.004856</td>\n",
              "      <td>-0.002122</td>\n",
              "      <td>0.004431</td>\n",
              "      <td>0.005323</td>\n",
              "      <td>-0.007501</td>\n",
              "      <td>0.004315</td>\n",
              "      <td>-0.002236</td>\n",
              "      <td>-0.005989</td>\n",
              "      <td>-0.000849</td>\n",
              "      <td>0.007535</td>\n",
              "      <td>-0.003045</td>\n",
              "      <td>-0.000337</td>\n",
              "      <td>-0.004859</td>\n",
              "      <td>0.001096</td>\n",
              "      <td>-0.014010</td>\n",
              "      <td>-0.003797</td>\n",
              "      <td>-0.000896</td>\n",
              "      <td>0.004697</td>\n",
              "      <td>0.001065</td>\n",
              "      <td>-0.001394</td>\n",
              "      <td>-0.006394</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004792</td>\n",
              "      <td>0.007404</td>\n",
              "      <td>-0.005944</td>\n",
              "      <td>0.013817</td>\n",
              "      <td>0.008303</td>\n",
              "      <td>0.011211</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.003302</td>\n",
              "      <td>-0.012332</td>\n",
              "      <td>-0.000625</td>\n",
              "      <td>0.004407</td>\n",
              "      <td>-0.010741</td>\n",
              "      <td>0.010471</td>\n",
              "      <td>3.328565e-03</td>\n",
              "      <td>0.004211</td>\n",
              "      <td>-0.001087</td>\n",
              "      <td>0.004841</td>\n",
              "      <td>0.005844</td>\n",
              "      <td>0.011151</td>\n",
              "      <td>0.017944</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.002454</td>\n",
              "      <td>-0.005007</td>\n",
              "      <td>0.008847</td>\n",
              "      <td>0.002119</td>\n",
              "      <td>-0.004608</td>\n",
              "      <td>-0.001125</td>\n",
              "      <td>-0.012019</td>\n",
              "      <td>0.005231</td>\n",
              "      <td>-0.011234</td>\n",
              "      <td>0.001708</td>\n",
              "      <td>-0.001072</td>\n",
              "      <td>0.004669</td>\n",
              "      <td>0.007096</td>\n",
              "      <td>0.004637</td>\n",
              "      <td>-0.002949</td>\n",
              "      <td>-0.005312</td>\n",
              "      <td>0.004070</td>\n",
              "      <td>0.008176</td>\n",
              "      <td>-0.008119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.001308</td>\n",
              "      <td>-0.000447</td>\n",
              "      <td>-0.006382</td>\n",
              "      <td>0.000843</td>\n",
              "      <td>0.001849</td>\n",
              "      <td>-0.000386</td>\n",
              "      <td>-0.005315</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.002657</td>\n",
              "      <td>-0.001101</td>\n",
              "      <td>0.006053</td>\n",
              "      <td>0.005212</td>\n",
              "      <td>-0.000678</td>\n",
              "      <td>-0.005576</td>\n",
              "      <td>-0.004032</td>\n",
              "      <td>-0.006276</td>\n",
              "      <td>-0.000396</td>\n",
              "      <td>-0.000683</td>\n",
              "      <td>0.004497</td>\n",
              "      <td>-0.002650</td>\n",
              "      <td>0.001387</td>\n",
              "      <td>0.005307</td>\n",
              "      <td>-0.001419</td>\n",
              "      <td>-0.003216</td>\n",
              "      <td>-0.004620</td>\n",
              "      <td>-0.003945</td>\n",
              "      <td>0.000641</td>\n",
              "      <td>0.002837</td>\n",
              "      <td>-0.000136</td>\n",
              "      <td>0.003659</td>\n",
              "      <td>0.005152</td>\n",
              "      <td>0.003192</td>\n",
              "      <td>0.002667</td>\n",
              "      <td>-0.003805</td>\n",
              "      <td>-0.000406</td>\n",
              "      <td>-0.002068</td>\n",
              "      <td>-0.000708</td>\n",
              "      <td>0.003073</td>\n",
              "      <td>0.003811</td>\n",
              "      <td>-0.000832</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005098</td>\n",
              "      <td>0.003582</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>0.002279</td>\n",
              "      <td>0.005982</td>\n",
              "      <td>0.003601</td>\n",
              "      <td>-0.003666</td>\n",
              "      <td>0.004465</td>\n",
              "      <td>0.000957</td>\n",
              "      <td>-0.005011</td>\n",
              "      <td>0.001262</td>\n",
              "      <td>-0.000135</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>5.341135e-07</td>\n",
              "      <td>0.002483</td>\n",
              "      <td>-0.001217</td>\n",
              "      <td>0.001249</td>\n",
              "      <td>0.001736</td>\n",
              "      <td>-0.001829</td>\n",
              "      <td>0.005459</td>\n",
              "      <td>-0.004162</td>\n",
              "      <td>0.003862</td>\n",
              "      <td>0.001172</td>\n",
              "      <td>-0.001073</td>\n",
              "      <td>-0.002760</td>\n",
              "      <td>-0.005752</td>\n",
              "      <td>0.003001</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>-0.002300</td>\n",
              "      <td>0.004329</td>\n",
              "      <td>-0.003366</td>\n",
              "      <td>-0.004595</td>\n",
              "      <td>0.001707</td>\n",
              "      <td>0.003599</td>\n",
              "      <td>0.002030</td>\n",
              "      <td>0.000315</td>\n",
              "      <td>-0.002722</td>\n",
              "      <td>0.001779</td>\n",
              "      <td>0.003574</td>\n",
              "      <td>-0.008453</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        97        98        99\n",
              "0  0.007446 -0.000986 -0.010638  ...  0.009802  0.002558 -0.013692\n",
              "1  0.008682 -0.002034 -0.001568  ...  0.010048  0.008154 -0.023768\n",
              "2  0.008094 -0.006639 -0.008165  ...  0.007443  0.010493 -0.029363\n",
              "3  0.004603 -0.005152 -0.004259  ...  0.004070  0.008176 -0.008119\n",
              "4  0.001308 -0.000447 -0.006382  ...  0.001779  0.003574 -0.008453\n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-3172xG5erJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1df6d5f4-d395-4d06-848d-34e8c66a03fa"
      },
      "source": [
        "grid_search.fit(data_train, y_train_2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=42,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'min_samples_leaf': [3, 4, 5],\n",
              "                         'n_estimators': [10, 50, 100, 200, 300, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM0UlDj4989D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71094822-f3bb-4e5e-d7c4-cebbb9c7d4dd"
      },
      "source": [
        "docs2v_best = grid_search.best_estimator_\n",
        "print(grid_search.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'min_samples_leaf': 5, 'n_estimators': 300}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogvheAUNAiwd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3dfe19e-dacc-425e-8676-5904dc285ca4"
      },
      "source": [
        "score_4 = docs2v_best.score(data_train, y_train_2)\n",
        "print(score_4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.961864406779661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcRxr8UjIkAr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e9daa97-a2d2-434b-f79a-f704657cdf11"
      },
      "source": [
        "y_pred_4 = docs2v_best.predict(data_test)\n",
        "acc_4 = accuracy_score(y_test_2, y_pred_4)\n",
        "print(acc_4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2769556025369979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiwGq29SIp8C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6bd1c934-0420-4da8-c2db-416412f48975"
      },
      "source": [
        "report_4 = classification_report(y_test_2, y_pred_4)\n",
        "print(report_4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           8       0.29      0.49      0.36       134\n",
            "          10       0.29      0.33      0.31       118\n",
            "          15       0.24      0.23      0.23       106\n",
            "          17       0.33      0.02      0.03       115\n",
            "\n",
            "    accuracy                           0.28       473\n",
            "   macro avg       0.29      0.27      0.23       473\n",
            "weighted avg       0.29      0.28      0.24       473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O7Y2grujD8R"
      },
      "source": [
        "**This result is showing overfitting**"
      ]
    }
  ]
}